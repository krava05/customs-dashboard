# ===============================================
# app.py - –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# –í–µ—Ä—Å–∏—è: 7.0
# –î–∞—Ç–∞: 2025-10-09
# –û–ø–∏—Å–∞–Ω–∏–µ: 
# - –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–º–ø–æ–Ω–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
# - –£–¥–∞–ª–µ–Ω –±–ª–æ–∫ "–ü—Ä–æ—Å—Ç–æ–π AI-–ø–æ–∏—Å–∫".
# - –î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–±—â–∞—è –∫–Ω–æ–ø–∫–∞ "–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã".
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
import json
from datetime import datetime

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö", layout="wide")

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- –§–£–ù–ö–¶–ò–Ø –ü–†–û–í–ï–†–ö–ò –ü–ê–†–û–õ–Ø ---
def check_password():
    def password_entered():
        if os.environ.get('K_SERVICE'): correct_password = os.environ.get("APP_PASSWORD")
        else: correct_password = st.secrets.get("APP_PASSWORD")
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True; del st.session_state["password"]
        else: st.session_state["password_correct"] = False
    if st.session_state.get("password_correct", False): return True
    st.text_input("–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø—É", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]: st.error("üòï –ü–∞—Ä–æ–ª—å –Ω–µ–≤—ñ—Ä–Ω–∏–π.")
    return False

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í GOOGLE ---
def initialize_clients():
    if 'clients_initialized' in st.session_state: return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤ Google: {e}")
        st.session_state.client_ready = False

# --- –§–£–ù–ö–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ---
@st.cache_data(ttl=3600)
def run_query(query, job_config=None):
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –¥–æ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# --- –§–£–ù–ö–¶–ò–Ø "AI-–ê–ù–ê–õ–ò–¢–ò–ö" ---
def get_analytical_ai_query(user_question, max_items=50):
    if not st.session_state.get('genai_ready', False):
        st.warning("AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤.")
        return None
    prompt = f"""
    You are an expert SQL analyst. Your task is to convert a user's analytical question into a single, executable Google BigQuery SQL query.
    DATABASE SCHEMA:
    The table is `{TABLE_ID}`. Columns are: data_deklaracii, napryamok ('–Ü–º–ø–æ—Ä—Ç' or '–ï–∫—Å–ø–æ—Ä—Ç'), nazva_kompanii, kod_yedrpou, kraina_partner, kod_uktzed, opis_tovaru, mytna_vartist_hrn, vaha_netto_kg, vyd_transportu.
    All text is in Ukrainian. The user's question may be in Russian or Ukrainian.
    INSTRUCTIONS:
    1.  Analyze the user's question to identify key entities (like companies, goods, countries) and metrics (total value, total weight, count of declarations).
    2.  If the user asks for a list of companies (e.g., "importers," "exporters"), you MUST use GROUP BY nazva_kompanii, kod_yedrpou.
    3.  Calculate aggregate metrics: COUNT(*) as declaration_count, SUM(mytna_vartist_hrn) as total_value_hrn, SUM(vaha_netto_kg) as total_weight_kg.
    4.  For semantic search on goods (e.g., "drone parts"), create a broad `REGEXP_CONTAINS` pattern for the `opis_tovaru` column. For "drone parts," search for terms like '–¥—Ä–æ–Ω', '–∫–≤–∞–¥—Ä–æ–∫–æ–ø—Ç–µ—Ä', '–±–ø–ª–∞', '–±–µ–∑–ø—ñ–ª–æ—Ç–Ω–∏–∫', '–ø—Ä–æ–ø–µ–ª–µ—Ä', '–∑–∞–ø—á–∞—Å—Ç–∏–Ω–∏ –¥–æ.*(–¥—Ä–æ–Ω|–±–ø–ª–∞)'.
    5.  Filter by `napryamok` if the user specifies "importers" (`'–Ü–º–ø–æ—Ä—Ç'`) or "exporters" (`'–ï–∫—Å–ø–æ—Ä—Ç'`).
    6.  Sort the results (`ORDER BY`) by the most relevant metric, in descending order.
    7.  Limit the results to {max_items}.
    8.  Return ONLY a valid JSON object with a single key "sql_query" containing the full SQL string.
    USER'S QUESTION: "{user_question}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        response = model.generate_content(prompt)
        response_text = response.text.strip().replace("```json", "").replace("```", "")
        response_json = json.loads(response_text)
        return response_json.get("sql_query")
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–æ–≥–æ SQL –∑–∞–ø–∏—Ç—É: {e}")
        return None

# --- –ó–ê–ì–†–£–ó–ö–ê –°–ü–ò–°–ö–û–í –î–õ–Ø –§–ò–õ–¨–¢–†–û–í ---
@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['–Ü–º–ø–æ—Ä—Ç', '–ï–∫—Å–ø–æ—Ä—Ç']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    return options

# --- –õ–û–ì–ò–ö–ê –°–ë–†–û–°–ê –§–ò–õ–¨–¢–†–û–í ---
def reset_all_filters():
    st.session_state.selected_directions = []
    st.session_state.selected_countries = []
    st.session_state.selected_transports = []
    st.session_state.selected_years = filter_options['years']
    st.session_state.weight_from = 0
    st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""
    st.session_state.yedrpou_input = ""
    st.session_state.company_input = ""

# --- –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
if not check_password():
    st.stop()

st.title("–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö üìà")
initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ Google BigQuery."); st.stop()

filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

# --- –†–ê–ó–î–ï–õ: AI-–ê–ù–ê–õ–ò–¢–ò–ö ---
st.header("ü§ñ AI-–ê–Ω–∞–ª–∏—Ç–∏–∫: –ó–∞–¥–∞–π—Ç–µ —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å")
ai_analytical_question = st.text_area(
    "–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –ù–∞–ø—Ä–∏–º–µ—Ä: '–ù–∞–π–¥–∏ —Ç–æ–ø-10 –∏–º–ø–æ—Ä—Ç–µ—Ä–æ–≤ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è –¥—Ä–æ–Ω–æ–≤ –ø–æ —Å—É–º–º–µ'",
    key="ai_analytical_question"
)
search_button_analytical_ai = st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é AI", type="primary")
if search_button_analytical_ai and ai_analytical_question:
    with st.spinner("‚ú® AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥—É–º–∞–µ—Ç..."):
        analytical_sql = get_analytical_ai_query(ai_analytical_question)
        if analytical_sql:
            st.subheader("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL-–∑–∞–ø—Ä–æ—Å:")
            st.code(analytical_sql, language='sql')
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å..."):
                analytical_results_df = run_query(analytical_sql)
                st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:")
                st.success(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(analytical_results_df)} –∑–∞–ø–∏—Å–µ–π.")
                st.dataframe(analytical_results_df)
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π SQL-–∑–∞–ø—Ä–æ—Å.")

st.divider()

# --- –°–ï–ö–¶–ò–Ø –§–ò–õ–¨–¢–†–û–í ---
st.header("üìä –†—É—á–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")
with st.expander("–ü–∞–Ω–µ–ª—å –§–∏–ª—å—Ç—Ä–æ–≤", expanded=True):
    st.button("–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã", on_click=reset_all_filters, use_container_width=True, type="secondary")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.multiselect("–ù–∞–ø—Ä—è–º–æ–∫:", options=filter_options['direction'], key='selected_directions')
    with col2:
        st.multiselect("–ö—Ä–∞—ó–Ω–∞-–ø–∞—Ä—Ç–Ω–µ—Ä:", options=filter_options['countries'], key='selected_countries')
    with col3:
        st.multiselect("–í–∏–¥ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É:", options=filter_options['transport'], key='selected_transports')

    col4, col5 = st.columns([2,1])
    with col4:
        st.multiselect("–†–æ–∫–∏:", options=filter_options['years'], key='selected_years')
    with col5:
        st.write("–í–∞–≥–∞ –Ω–µ—Ç—Ç–æ, –∫–≥")
        weight_col1, weight_col2 = st.columns(2)
        weight_from = weight_col1.number_input("–í—ñ–¥", min_value=0, step=100, key="weight_from")
        weight_to = weight_col2.number_input("–î–æ", min_value=0, step=100, key="weight_to")

    col6, col7, col8 = st.columns(3)
    with col6:
        st.text_input("–ö–æ–¥ –£–ö–¢–ó–ï–î (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='uktzed_input')
    with col7:
        st.text_input("–ö–æ–¥ –Ñ–î–†–ü–û–£ (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='yedrpou_input')
    with col8:
        st.text_input("–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='company_input')
    
    search_button_filters = st.button("üîç –ó–Ω–∞–π—Ç–∏ –∑–∞ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏", use_container_width=True, type="primary")

# --- –õ–û–ì–ò–ö–ê –§–ò–õ–¨–¢–†–û–í ---
if search_button_filters:
    query_parts = []
    query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]

    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)")
        query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)")
        query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)")
        query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)")
        query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))

    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from")
        query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to")
        query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))

    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"
            conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")

    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)")
        query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))

    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"
            conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    
    if not query_parts:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ—ñ–ª—å—Ç—Ä.")
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 1000"
        job_config = QueryJobConfig(query_parameters=query_params)
        st.code(final_query, language='sql')
        with st.spinner("–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –∑–∞–ø–∏—Ç..."):
            results_df = run_query(final_query, job_config=job_config)
            st.success(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –∑–∞–ø–∏—Å—ñ–≤.")
            st.dataframe(results_df)
