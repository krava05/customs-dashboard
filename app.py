# ===============================================
# app.py - Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚Ð°Ð¼Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
# Ð’ÐµÑ€ÑÐ¸Ñ: 15.1
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import re

# --- ÐšÐžÐÐ¤Ð˜Ð“Ð£Ð ÐÐ¦Ð˜Ð¯ ---
APP_VERSION = "Ð’ÐµÑ€ÑÐ¸Ñ 15.1"
st.set_page_config(page_title="ÐÐ½Ð°Ð»Ñ–Ñ‚Ð¸ÐºÐ° ÐœÐ¸Ñ‚Ð½Ð¸Ñ… Ð”Ð°Ð½Ð¸Ñ…", layout="wide")
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ ---

def check_password():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð¿Ð°Ñ€Ð¾Ð»ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑŽ."""
    def password_entered():
        if os.environ.get('K_SERVICE'):
            correct_password = os.environ.get("APP_PASSWORD")
        else:
            correct_password = st.secrets.get("APP_PASSWORD")
        
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if st.session_state.get("password_correct", False):
        return True
    
    st.text_input("Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð°Ñ€Ð¾Ð»ÑŒ Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]:
        st.error("ðŸ˜• ÐŸÐ°Ñ€Ð¾Ð»ÑŒ Ð½ÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹.")
    return False

def initialize_clients():
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ BigQuery Ð¸ Generative AI."""
    if 'clients_initialized' in st.session_state:
        return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
            
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ— Ð² Google: {e}")
        st.session_state.client_ready = False

def run_query(query, job_config=None):
    """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº BigQuery Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ DataFrame."""
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ð´Ð¾ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def get_ai_code_suggestions(product_description):
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¾Ñ‚ AI ÑÐ¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐ¾Ñ€ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÐºÐ¾Ð´Ð¾Ð² Ð£ÐšÐ¢Ð—Ð•Ð”."""
    if not st.session_state.get('genai_ready', False):
        return None
    
    prompt = f"""
    Ð¢Ð¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Ð· Ð¼Ð¸Ñ‚Ð½Ð¾Ñ— ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ— Ñ‚Ð° ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¸Ñ… ÐºÐ¾Ð´Ñ–Ð² Ð£ÐšÐ¢Ð—Ð•Ð”.
    ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð¾Ð¿Ð¸Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ñƒ Ñ‚Ð° Ð½Ð°Ð´Ð°Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¸Ñ… ÐºÐ¾Ð´Ñ–Ð² Ð£ÐšÐ¢Ð—Ð•Ð”.
    Ð’ÐºÐ»ÑŽÑ‡Ð¸ ÐºÐ¾Ð´Ð¸ Ñ€Ñ–Ð·Ð½Ð¾Ñ— Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´, 4, 6, 10 Ð·Ð½Ð°ÐºÑ–Ð²).

    Ð¢Ð²Ð¾Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ ÐœÐÐ„ Ð‘Ð£Ð¢Ð˜ Ð¢Ð†Ð›Ð¬ÐšÐ˜ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– JSON, Ñ‰Ð¾ Ñ” Ñ”Ð´Ð¸Ð½Ð¸Ð¼ ÑÐ¿Ð¸ÑÐºÐ¾Ð¼ Ñ€ÑÐ´ÐºÑ–Ð².
    ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ñ— Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–: ["8517", "851712", "8517120000"]
    ÐÐµ Ð´Ð¾Ð´Ð°Ð²Ð°Ð¹ Ð¶Ð¾Ð´Ð½Ð¸Ñ… Ð¾Ð¿Ð¸ÑÑ–Ð², Ð¿Ð¾ÑÑÐ½ÐµÐ½ÑŒ Ñ‡Ð¸ Ñ–Ð½ÑˆÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ñƒ Ð¿Ð¾Ð·Ð° Ð¼ÐµÐ¶Ð°Ð¼Ð¸ JSON-Ð¼Ð°ÑÐ¸Ð²Ñƒ.

    ÐžÐŸÐ˜Ð¡ Ð¢ÐžÐ’ÐÐ Ð£: "{product_description}"
    """
    try:
        # --- Ð˜Ð—ÐœÐ•ÐÐ•ÐÐ˜Ð• Ð—Ð”Ð•Ð¡Ð¬ ---
        model = genai.GenerativeModel('models/gemini-pro-latest')
        # -------------------------
        
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = model.generate_content(prompt, generation_config=generation_config)
        
        cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        response_json = json.loads(cleaned_text)

        if isinstance(response_json, list) and all(isinstance(i, str) for i in response_json):
            return response_json
        else:
            st.error("AI Ð¿Ð¾Ð²ÐµÑ€Ð½ÑƒÐ² Ð´Ð°Ð½Ñ– Ñƒ Ð½ÐµÐ¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¾Ð¼Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–.")
            return []
            
    except Exception as e:
        st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ– ÐºÐ¾Ð´Ñ–Ð² Ð²Ñ–Ð´ AI: {e}")
        return None

def find_and_validate_codes(product_description):
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÐºÐ¾Ð´Ñ‹ Ð¾Ñ‚ AI Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð¸Ñ… Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… BigQuery."""
    
    # 1. ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‚ÐµÐ¾Ñ€ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐºÐ¾Ð´Ñ‹ Ð¾Ñ‚ AI
    theoretical_codes = get_ai_code_suggestions(product_description)
    
    if theoretical_codes is None or not theoretical_codes:
        st.warning("AI Ð½Ðµ Ð·Ð¼Ñ–Ð³ Ð·Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð´Ð¸. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð¾Ð¿Ð¸Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ñƒ.")
        return None, [], []

    unique_codes = list(set(filter(None, theoretical_codes)))
    if not unique_codes:
        st.warning("Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ AI Ð½Ðµ Ð¼Ñ–ÑÑ‚Ð¸Ñ‚ÑŒ ÐºÐ¾Ð´Ñ–Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸.")
        return None, [], []

    # 2. ÐŸÐ¾ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÐºÐ¾Ð´Ð¾Ð² Ð² BigQuery
    query_parts = []
    query_params = []
    for i, code in enumerate(unique_codes):
        param_name = f"code{i}"
        query_parts.append(f"STARTS_WITH(kod_uktzed, @{param_name})")
        query_params.append(ScalarQueryParameter(param_name, "STRING", code))
        
    where_clause = " OR ".join(query_parts)
    
    validation_query = f"""
    WITH RankedDescriptions AS (
      SELECT
        kod_uktzed,
        opis_tovaru,
        COUNT(*) AS cnt,
        ROW_NUMBER() OVER(PARTITION BY kod_uktzed ORDER BY COUNT(*) DESC) as rn
      FROM `{TABLE_ID}`
      WHERE ({where_clause}) AND kod_uktzed IS NOT NULL
      GROUP BY kod_uktzed, opis_tovaru
    ),
    TotalCounts AS (
      SELECT kod_uktzed, SUM(cnt) as total_declarations
      FROM RankedDescriptions
      GROUP BY kod_uktzed
    )
    SELECT
      rd.kod_uktzed AS "ÐšÐ¾Ð´ Ð£ÐšÐ¢Ð—Ð•Ð” Ð² Ð±Ð°Ð·Ñ–",
      rd.opis_tovaru AS "ÐÐ°Ð¹Ñ‡Ð°ÑÑ‚Ñ–ÑˆÐ¸Ð¹ Ð¾Ð¿Ð¸Ñ Ð² Ð±Ð°Ð·Ñ–",
      tc.total_declarations AS "ÐšÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ†Ñ–Ð¹"
    FROM RankedDescriptions rd
    JOIN TotalCounts tc ON rd.kod_uktzed = tc.kod_uktzed
    WHERE rd.rn = 1
    ORDER BY tc.total_declarations DESC
    LIMIT 50
    """
    
    job_config = QueryJobConfig(query_parameters=query_params)
    validated_df = run_query(validation_query, job_config=job_config)
    
    # 3. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ, ÐºÐ°ÐºÐ¸Ðµ Ð¸Ð· Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ… AI ÐºÐ¾Ð´Ð¾Ð² Ð´Ð°Ð»Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
    found_prefixes = set()
    if not validated_df.empty:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ñ ÐºÐ¾Ð´Ð°Ð¼Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ð°ÑˆÐ»Ð¸ÑÑŒ Ð² Ð±Ð°Ð·Ðµ
        db_codes_series = validated_df["ÐšÐ¾Ð´ Ð£ÐšÐ¢Ð—Ð•Ð” Ð² Ð±Ð°Ð·Ñ–"]
        for db_code in db_codes_series:
            for ai_code in unique_codes:
                if str(db_code).startswith(ai_code):
                    found_prefixes.add(ai_code)
    
    unfound_codes = set(unique_codes) - found_prefixes
    
    return validated_df, list(found_prefixes), list(unfound_codes)


@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚', 'Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    return options

def reset_all_filters():
    st.session_state.selected_directions = []
    st.session_state.selected_countries = []
    st.session_state.selected_transports = []
    st.session_state.selected_years = []
    st.session_state.weight_from = 0
    st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""
    st.session_state.yedrpou_input = ""
    st.session_state.company_input = ""

# --- ÐžÐ¡ÐÐžÐ’ÐÐžÐ™ Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡ ÐŸÐ Ð˜Ð›ÐžÐ–Ð•ÐÐ˜Ð¯ ---

if not check_password():
    st.stop()

st.sidebar.info(APP_VERSION)
st.title("ÐÐ½Ð°Ð»Ñ–Ñ‚Ð¸ÐºÐ° ÐœÐ¸Ñ‚Ð½Ð¸Ñ… Ð”Ð°Ð½Ð¸Ñ… ðŸ“ˆ")

initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸ÑÑ Ð´Ð¾ Google BigQuery.")
    st.stop()

# --- Ð‘Ð›ÐžÐš AI-ÐŸÐžÐœÐžÐ©ÐÐ˜ÐšÐ ---
st.header("ðŸ¤– AI-Ð¿Ð¾Ð¼Ñ–Ñ‡Ð½Ð¸Ðº Ð¿Ð¾ ÐºÐ¾Ð´Ð°Ð¼ Ð£ÐšÐ¢Ð—Ð•Ð”")
ai_code_description = st.text_input("Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¾Ð¿Ð¸Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ñƒ Ð´Ð»Ñ Ð¿Ð¾ÑˆÑƒÐºÑƒ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¸Ñ… ÐºÐ¾Ð´Ñ–Ð² Ñƒ Ð²Ð°ÑˆÑ–Ð¹ Ð±Ð°Ð·Ñ–:", key="ai_code_helper_input")

if st.button("ðŸ’¡ Ð—Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ñ‚Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÐºÐ¾Ð´Ð¸", type="primary"):
    if ai_code_description:
        with st.spinner("AI Ð¿Ñ–Ð´Ð±Ð¸Ñ€Ð°Ñ” ÐºÐ¾Ð´Ð¸, Ð° Ð¼Ð¸ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ—Ñ… Ñƒ Ð±Ð°Ð·Ñ–..."):
            validated_df, found, unfound = find_and_validate_codes(ai_code_description)
            st.session_state.validated_codes_df = validated_df
            st.session_state.found_ai_codes = found
            st.session_state.unfound_ai_codes = unfound
    else:
        st.warning("Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¾Ð¿Ð¸Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ñƒ.")

if 'validated_codes_df' in st.session_state:
    validated_df = st.session_state.validated_codes_df
    
    if validated_df is not None and not validated_df.empty:
        st.success(f"âœ… Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(validated_df)} Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¸Ñ… ÐºÐ¾Ð´Ñ–Ð² Ñƒ Ð²Ð°ÑˆÑ–Ð¹ Ð±Ð°Ð·Ñ– Ð´Ð°Ð½Ð¸Ñ…:")
        st.dataframe(validated_df, use_container_width=True)
        if st.session_state.found_ai_codes:
            st.info(f"ÐšÐ¾Ð´Ð¸ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð·Ð° Ñ†Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–ÑÐ¼Ð¸ AI: `{', '.join(st.session_state.found_ai_codes)}`")
    else:
        st.warning("ðŸš« Ð£ Ð²Ð°ÑˆÑ–Ð¹ Ð±Ð°Ð·Ñ– Ð´Ð°Ð½Ð¸Ñ… Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¶Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ñƒ, Ñ‰Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ñ” Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–ÑÐ¼ AI.")

    if st.session_state.unfound_ai_codes:
        st.caption(f"Ð¢ÐµÐ¾Ñ€ÐµÑ‚Ð¸Ñ‡Ð½Ñ– ÐºÐ¾Ð´Ð¸ Ð²Ñ–Ð´ AI, Ð´Ð»Ñ ÑÐºÐ¸Ñ… Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð·Ð±Ñ–Ð³Ñ–Ð²: `{', '.join(st.session_state.unfound_ai_codes)}`")

    if st.button("ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ AI", type="secondary"):
        keys_to_delete = ['validated_codes_df', 'found_ai_codes', 'unfound_ai_codes']
        for key in keys_to_delete:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

st.divider()

# --- Ð‘Ð›ÐžÐš Ð Ð£Ð§ÐÐ«Ð¥ Ð¤Ð˜Ð›Ð¬Ð¢Ð ÐžÐ’ ---
filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

st.header("ðŸ“Š Ð ÑƒÑ‡Ð½Ñ– Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¸")
with st.expander("ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð¤Ñ–Ð»ÑŒÑ‚Ñ€Ñ–Ð²", expanded=True):
    st.button("Ð¡ÐºÐ¸Ð½ÑƒÑ‚Ð¸ Ð²ÑÑ– Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¸", on_click=reset_all_filters, use_container_width=True, type="secondary")
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1: st.multiselect("ÐÐ°Ð¿Ñ€ÑÐ¼Ð¾Ðº:", options=filter_options['direction'], key='selected_directions')
    with col2: st.multiselect("ÐšÑ€Ð°Ñ—Ð½Ð°-Ð¿Ð°Ñ€Ñ‚Ð½ÐµÑ€:", options=filter_options['countries'], key='selected_countries')
    with col3: st.multiselect("Ð’Ð¸Ð´ Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ñƒ:", options=filter_options['transport'], key='selected_transports')
    col4, col5 = st.columns([2,1])
    with col4: st.multiselect("Ð Ð¾ÐºÐ¸:", options=filter_options['years'], key='selected_years')
    with col5:
        st.write("Ð’Ð°Ð³Ð° Ð½ÐµÑ‚Ñ‚Ð¾, ÐºÐ³")
        weight_col1, weight_col2 = st.columns(2)
        weight_from = weight_col1.number_input("Ð’Ñ–Ð´", min_value=0, step=100, key="weight_from")
        weight_to = weight_col2.number_input("Ð”Ð¾", min_value=0, step=100, key="weight_to")
    col6, col7, col8 = st.columns(3)
    with col6: st.text_input("ÐšÐ¾Ð´ Ð£ÐšÐ¢Ð—Ð•Ð” (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='uktzed_input')
    with col7: st.text_input("ÐšÐ¾Ð´ Ð„Ð”Ð ÐŸÐžÐ£ (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='yedrpou_input')
    with col8: st.text_input("ÐÐ°Ð·Ð²Ð° ÐºÐ¾Ð¼Ð¿Ð°Ð½Ñ–Ñ— (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='company_input')
    search_button_filters = st.button("ðŸ” Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ð·Ð° Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð°Ð¼Ð¸", use_container_width=True, type="primary")

if search_button_filters:
    query_parts = []; query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]
    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)")
        query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)")
        query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)")
        query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)")
        query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))
    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from")
        query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to")
        query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))
    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"
            conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)")
        query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))
    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"
            conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    
    if not query_parts:
        st.warning("Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ…Ð¾Ñ‡Ð° Ð± Ð¾Ð´Ð¸Ð½ Ñ„Ñ–Ð»ÑŒÑ‚Ñ€.")
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 1000"
        job_config = QueryJobConfig(query_parameters=query_params)
        with st.spinner("Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ”Ñ‚ÑŒÑÑ Ð·Ð°Ð¿Ð¸Ñ‚..."):
            results_df = run_query(final_query, job_config=job_config)
            st.success(f"Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(results_df)} Ð·Ð°Ð¿Ð¸ÑÑ–Ð².")
            st.dataframe(results_df)
