# ===============================================
# app.py - –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# –í–µ—Ä—Å–∏—è: 15.1
# –î–∞—Ç–∞: 2025-10-10
# –û–ø–∏—Å–∞–Ω–∏–µ: 
# - –ò–°–ü–†–ê–í–õ–ï–ù–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª–Ω—ã–π –∫–æ–¥ 
#   –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è IndentationError.
# - "AI-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∫–æ–¥–∞–º" —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
from datetime import datetime
import re

# --- –í–ï–†–°–ò–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
APP_VERSION = "–í–µ—Ä—Å–∏—è 15.1"

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö", layout="wide")

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- –§–£–ù–ö–¶–ò–Ø –ü–†–û–í–ï–†–ö–ò –ü–ê–†–û–õ–Ø ---
def check_password():
    def password_entered():
        if os.environ.get('K_SERVICE'): correct_password = os.environ.get("APP_PASSWORD")
        else: correct_password = st.secrets.get("APP_PASSWORD")
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True; del st.session_state["password"]
        else: st.session_state["password_correct"] = False
    if st.session_state.get("password_correct", False): return True
    st.text_input("–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø—É", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]: st.error("üòï –ü–∞—Ä–æ–ª—å –Ω–µ–≤—ñ—Ä–Ω–∏–π.")
    return False

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í GOOGLE ---
def initialize_clients():
    if 'clients_initialized' in st.session_state: return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤ Google: {e}")
        st.session_state.client_ready = False

# --- –§–£–ù–ö–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ---
def run_query(query, job_config=None):
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –¥–æ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# --- –§–£–ù–ö–¶–ò–Ø "AI-–ê–ù–ê–õ–ò–¢–ò–ö" ---
def get_analytical_ai_query(user_question, max_items=50):
    if not st.session_state.get('genai_ready', False): return None
    prompt = f"""
    You are a SQL generation machine... USER'S QUESTION: "{user_question}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        safety_settings = { HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE }
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = model.generate_content(prompt, generation_config=generation_config, safety_settings=safety_settings)
        response_json = json.loads(response.text)
        return response_json.get("sql_query")
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–æ–≥–æ SQL –∑–∞–ø–∏—Ç—É: {e}")
        return None

# --- –§–£–ù–ö–¶–ò–Ø "AI-–ü–û–ú–û–©–ù–ò–ö –ü–û –ö–û–î–ê–ú" ---
def get_ai_code_suggestions(product_description):
    if not st.session_state.get('genai_ready', False): return None
    prompt = f"""
    You are an expert in customs classification and Ukrainian HS codes (–£–ö–¢–ó–ï–î)... USER'S PRODUCT DESCRIPTION: "{product_description}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        safety_settings = { HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE }
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = model.generate_content(prompt, generation_config=generation_config, safety_settings=safety_settings)
        response_json = json.loads(response.text)
        if isinstance(response_json, dict):
            return response_json.get("suggestions", [])
        elif isinstance(response_json, list):
            return response_json
        else:
            return []
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–¥–æ–≤ –æ—Ç AI: {e}")
        return None

# --- –ó–ê–ì–†–£–ó–ö–ê –°–ü–ò–°–ö–û–í –î–õ–Ø –§–ò–õ–¨–¢–†–û–í ---
@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['–Ü–º–ø–æ—Ä—Ç', '–ï–∫—Å–ø–æ—Ä—Ç']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    return options

# --- –õ–û–ì–ò–ö–ê –°–ë–†–û–°–ê –§–ò–õ–¨–¢–†–û–í ---
def reset_all_filters():
    st.session_state.selected_directions = []
    st.session_state.selected_countries = []
    st.session_state.selected_transports = []
    st.session_state.selected_years = []
    st.session_state.weight_from = 0
    st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""
    st.session_state.yedrpou_input = ""
    st.session_state.company_input = ""

# --- –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
if not check_password():
    st.stop()

st.markdown(f"""<div style="position: fixed; top: 55px; right: 15px; font-size: 0.8em; color: gray; z-index: 100;">{APP_VERSION}</div>""", unsafe_allow_html=True)
st.title("–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö üìà")
initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ Google BigQuery."); st.stop()

filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

# --- –†–ê–ó–î–ï–õ: AI-–ê–ù–ê–õ–ò–¢–ò–ö ---
st.header("ü§ñ AI-–ê–Ω–∞–ª–∏—Ç–∏–∫: –ó–∞–¥–∞–π—Ç–µ —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å")
ai_analytical_question = st.text_area("–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å...", key="ai_analytical_question")
search_button_analytical_ai = st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é AI", type="primary")
if search_button_analytical_ai and ai_analytical_question:
    with st.spinner("‚ú® AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥—É–º–∞–µ—Ç..."):
        analytical_sql = get_analytical_ai_query(ai_analytical_question)
        if analytical_sql:
            st.code(analytical_sql, language='sql')
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å..."):
                analytical_results_df = run_query(analytical_sql)
                st.dataframe(analytical_results_df)
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π SQL-–∑–∞–ø—Ä–æ—Å.")

st.divider()

# --- –†–ê–ó–î–ï–õ: AI-–ü–û–ú–û–©–ù–ò–ö –ü–û –ö–û–î–ê–ú ---
st.header("ü§ñ AI-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∫–æ–¥–∞–º –£–ö–¢–ó–ï–î")
ai_code_description = st.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞...", key="ai_code_helper_input")
if st.button("–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∫–æ–¥—ã"):
    if ai_code_description:
        with st.spinner("–≠—Ç–∞–ø 1/2: AI –ø–æ–¥–±–∏—Ä–∞–µ—Ç —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–¥—ã..."):
            theoretical_codes = get_ai_code_suggestions(ai_code_description)
        if theoretical_codes:
            df_theoretical = pd.DataFrame(theoretical_codes)
            code_list = df_theoretical['code'].tolist()
            with st.spinner("–≠—Ç–∞–ø 2/2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–æ–≤ –≤ –≤–∞—à–µ–π –±–∞–∑–µ..."):
                query_check = f"SELECT kod_uktzed, COUNT(*) as usage_count FROM `{TABLE_ID}` WHERE kod_uktzed IN UNNEST(@codes) GROUP BY kod_uktzed"
                job_config_check = QueryJobConfig(query_parameters=[ArrayQueryParameter("codes", "STRING", code_list)])
                df_existing = run_query(query_check, job_config=job_config_check)
                if not df_existing.empty:
                    df_final = pd.merge(df_theoretical, df_existing, left_on='code', right_on='kod_uktzed', how='inner')
                    df_final = df_final.rename(columns={'code': '–ö–æ–¥', 'description': '–û–ø–∏—Å–∞–Ω–∏–µ', 'usage_count': '–ö–æ–ª-–≤–æ –≤ –±–∞–∑–µ'})
                    st.session_state.suggested_codes_table = df_final[['–ö–æ–¥', '–û–ø–∏—Å–∞–Ω–∏–µ', '–ö–æ–ª-–≤–æ –≤ –±–∞–∑–µ']].sort_values(by='–ö–æ–ª-–≤–æ –≤ –±–∞–∑–µ', ascending=False)
                else:
                    st.session_state.suggested_codes_table = pd.DataFrame()
        else:
            st.session_state.suggested_codes_table = None
    else:
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞.")

if 'suggested_codes_table' in st.session_state and st.session_state.suggested_codes_table is not None:
    if not st.session_state.suggested_codes_table.empty:
        st.success("–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–¥–æ–≤ —Å –≤–∞—à–µ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö:")
        st.dataframe(st.session_state.suggested_codes_table, use_container_width=True)
    else:
        st.info("AI –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–¥—ã, –Ω–æ –Ω–∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –ø–æ–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≤–∞—à–µ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", type="secondary"):
        st.session_state.suggested_codes_table = None
        st.rerun()

st.divider()

# --- –°–ï–ö–¶–ò–Ø –†–£–ß–ù–´–• –§–ò–õ–¨–¢–†–û–í ---
st.header("üìä –†—É—á–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")
with st.expander("–ü–∞–Ω–µ–ª—å –§–∏–ª—å—Ç—Ä–æ–≤", expanded=True):
    st.button("–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã", on_click=reset_all_filters, use_container_width=True, type="secondary")
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1: st.multiselect("–ù–∞–ø—Ä—è–º–æ–∫:", options=filter_options['direction'], key='selected_directions')
    with col2: st.multiselect("–ö—Ä–∞—ó–Ω–∞-–ø–∞—Ä—Ç–Ω–µ—Ä:", options=filter_options['countries'], key='selected_countries')
    with col3: st.multiselect("–í–∏–¥ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É:", options=filter_options['transport'], key='selected_transports')
    col4, col5 = st.columns([2,1])
    with col4: st.multiselect("–†–æ–∫–∏:", options=filter_options['years'], key='selected_years')
    with col5:
        st.write("–í–∞–≥–∞ –Ω–µ—Ç—Ç–æ, –∫–≥")
        weight_col1, weight_col2 = st.columns(2)
        weight_from = weight_col1.number_input("–í—ñ–¥", min_value=0, step=100, key="weight_from")
        weight_to = weight_col2.number_input("–î–æ", min_value=0, step=100, key="weight_to")
    col6, col7, col8 = st.columns(3)
    with col6: st.text_input("–ö–æ–¥ –£–ö–¢–ó–ï–î (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='uktzed_input')
    with col7: st.text_input("–ö–æ–¥ –Ñ–î–†–ü–û–£ (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='yedrpou_input')
    with col8: st.text_input("–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='company_input')
    search_button_filters = st.button("üîç –ó–Ω–∞–π—Ç–∏ –∑–∞ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏", use_container_width=True, type="primary")

# --- –õ–û–ì–ò–ö–ê –§–ò–õ–¨–¢–†–û–í ---
if search_button_filters:
    query_parts = []; query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]
    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)")
        query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)")
        query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)")
        query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)")
        query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))
    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from")
        query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to")
        query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))
    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"
            conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)")
        query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))
    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"
            conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    if not query_parts:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ—ñ–ª—å—Ç—Ä.")
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 1000"
        job_config = QueryJobConfig(query_parameters=query_params)
        st.code(final_query, language='sql')
        with st.spinner("–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –∑–∞–ø–∏—Ç..."):
            results_df = run_query(final_query, job_config=job_config)
            st.success(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –∑–∞–ø–∏—Å—ñ–≤.")
            st.dataframe(results_df)
