# ===============================================
# app.py - Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚Ð°Ð¼Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
# Ð’ÐµÑ€ÑÐ¸Ñ: 7.0
# Ð”Ð°Ñ‚Ð°: 2025-10-09
# ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ: 
# - Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÐºÐ¾Ð¼Ð¿Ð¾Ð½Ð¾Ð²ÐºÐ° Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°.
# - Ð£Ð´Ð°Ð»ÐµÐ½ Ð±Ð»Ð¾Ðº "ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ AI-Ð¿Ð¾Ð¸ÑÐº".
# - Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð¾Ð±Ñ‰Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ° "Ð¡Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð²ÑÐµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹".
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
import json
from datetime import datetime

# --- ÐšÐžÐÐ¤Ð˜Ð“Ð£Ð ÐÐ¦Ð˜Ð¯ Ð¡Ð¢Ð ÐÐÐ˜Ð¦Ð« ---
st.set_page_config(page_title="ÐÐ½Ð°Ð»Ñ–Ñ‚Ð¸ÐºÐ° ÐœÐ¸Ñ‚Ð½Ð¸Ñ… Ð”Ð°Ð½Ð¸Ñ…", layout="wide")

# --- Ð“Ð›ÐžÐ‘ÐÐ›Ð¬ÐÐ«Ð• ÐŸÐ•Ð Ð•ÐœÐ•ÐÐÐ«Ð• ---
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯ ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ˜ ÐŸÐÐ ÐžÐ›Ð¯ ---
def check_password():
    def password_entered():
        if os.environ.get('K_SERVICE'): correct_password = os.environ.get("APP_PASSWORD")
        else: correct_password = st.secrets.get("APP_PASSWORD")
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True; del st.session_state["password"]
        else: st.session_state["password_correct"] = False
    if st.session_state.get("password_correct", False): return True
    st.text_input("Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð°Ñ€Ð¾Ð»ÑŒ Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]: st.error("ðŸ˜• ÐŸÐ°Ñ€Ð¾Ð»ÑŒ Ð½ÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹.")
    return False

# --- Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ ÐšÐ›Ð˜Ð•ÐÐ¢ÐžÐ’ GOOGLE ---
def initialize_clients():
    if 'clients_initialized' in st.session_state: return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ— Ð² Google: {e}")
        st.session_state.client_ready = False

# --- Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯ Ð—ÐÐ“Ð Ð£Ð—ÐšÐ˜ Ð”ÐÐÐÐ«Ð¥ ---
@st.cache_data(ttl=3600)
def run_query(query, job_config=None):
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ð´Ð¾ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# --- Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯ "AI-ÐÐÐÐ›Ð˜Ð¢Ð˜Ðš" ---
def get_analytical_ai_query(user_question, max_items=50):
    if not st.session_state.get('genai_ready', False):
        st.warning("AI-ÑÐµÑ€Ð²Ð¸Ñ Ð½Ðµ Ð³Ð¾Ñ‚Ð¾Ð².")
        return None
    prompt = f"""
    You are an expert SQL analyst. Your task is to convert a user's analytical question into a single, executable Google BigQuery SQL query.
    DATABASE SCHEMA:
    The table is `{TABLE_ID}`. Columns are: data_deklaracii, napryamok ('Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚' or 'Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚'), nazva_kompanii, kod_yedrpou, kraina_partner, kod_uktzed, opis_tovaru, mytna_vartist_hrn, vaha_netto_kg, vyd_transportu.
    All text is in Ukrainian. The user's question may be in Russian or Ukrainian.
    INSTRUCTIONS:
    1.  Analyze the user's question to identify key entities (like companies, goods, countries) and metrics (total value, total weight, count of declarations).
    2.  If the user asks for a list of companies (e.g., "importers," "exporters"), you MUST use GROUP BY nazva_kompanii, kod_yedrpou.
    3.  Calculate aggregate metrics: COUNT(*) as declaration_count, SUM(mytna_vartist_hrn) as total_value_hrn, SUM(vaha_netto_kg) as total_weight_kg.
    4.  For semantic search on goods (e.g., "drone parts"), create a broad `REGEXP_CONTAINS` pattern for the `opis_tovaru` column. For "drone parts," search for terms like 'Ð´Ñ€Ð¾Ð½', 'ÐºÐ²Ð°Ð´Ñ€Ð¾ÐºÐ¾Ð¿Ñ‚ÐµÑ€', 'Ð±Ð¿Ð»Ð°', 'Ð±ÐµÐ·Ð¿Ñ–Ð»Ð¾Ñ‚Ð½Ð¸Ðº', 'Ð¿Ñ€Ð¾Ð¿ÐµÐ»ÐµÑ€', 'Ð·Ð°Ð¿Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸ Ð´Ð¾.*(Ð´Ñ€Ð¾Ð½|Ð±Ð¿Ð»Ð°)'.
    5.  Filter by `napryamok` if the user specifies "importers" (`'Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚'`) or "exporters" (`'Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚'`).
    6.  Sort the results (`ORDER BY`) by the most relevant metric, in descending order.
    7.  Limit the results to {max_items}.
    8.  Return ONLY a valid JSON object with a single key "sql_query" containing the full SQL string.
    USER'S QUESTION: "{user_question}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        response = model.generate_content(prompt)
        response_text = response.text.strip().replace("```json", "").replace("```", "")
        response_json = json.loads(response_text)
        return response_json.get("sql_query")
    except Exception as e:
        st.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ— Ð°Ð½Ð°Ð»Ñ–Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ SQL Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ: {e}")
        return None

# --- Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð¡ÐŸÐ˜Ð¡ÐšÐžÐ’ Ð”Ð›Ð¯ Ð¤Ð˜Ð›Ð¬Ð¢Ð ÐžÐ’ ---
@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚', 'Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    return options

# --- Ð›ÐžÐ“Ð˜ÐšÐ Ð¡Ð‘Ð ÐžÐ¡Ð Ð¤Ð˜Ð›Ð¬Ð¢Ð ÐžÐ’ ---
def reset_all_filters():
    st.session_state.selected_directions = []
    st.session_state.selected_countries = []
    st.session_state.selected_transports = []
    st.session_state.selected_years = filter_options['years']
    st.session_state.weight_from = 0
    st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""
    st.session_state.yedrpou_input = ""
    st.session_state.company_input = ""

# --- ÐžÐ¡ÐÐžÐ’ÐÐžÐ™ Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡ ÐŸÐ Ð˜Ð›ÐžÐ–Ð•ÐÐ˜Ð¯ ---
if not check_password():
    st.stop()

st.title("ÐÐ½Ð°Ð»Ñ–Ñ‚Ð¸ÐºÐ° ÐœÐ¸Ñ‚Ð½Ð¸Ñ… Ð”Ð°Ð½Ð¸Ñ… ðŸ“ˆ")
initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸ÑÑ Ð´Ð¾ Google BigQuery."); st.stop()

filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

# --- Ð ÐÐ—Ð”Ð•Ð›: AI-ÐÐÐÐ›Ð˜Ð¢Ð˜Ðš ---
st.header("ðŸ¤– AI-ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸Ðº: Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ")
ai_analytical_question = st.text_area(
    "Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 'ÐÐ°Ð¹Ð´Ð¸ Ñ‚Ð¾Ð¿-10 Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚ÐµÑ€Ð¾Ð² Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ Ð´Ð»Ñ Ð´Ñ€Ð¾Ð½Ð¾Ð² Ð¿Ð¾ ÑÑƒÐ¼Ð¼Ðµ'",
    key="ai_analytical_question"
)
search_button_analytical_ai = st.button("ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ AI", type="primary")
if search_button_analytical_ai and ai_analytical_question:
    with st.spinner("âœ¨ AI-Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ð´ÑƒÐ¼Ð°ÐµÑ‚..."):
        analytical_sql = get_analytical_ai_query(ai_analytical_question)
        if analytical_sql:
            st.subheader("Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ SQL-Ð·Ð°Ð¿Ñ€Ð¾Ñ:")
            st.code(analytical_sql, language='sql')
            with st.spinner("Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ..."):
                analytical_results_df = run_query(analytical_sql)
                st.subheader("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
                st.success(f"ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½. ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(analytical_results_df)} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹.")
                st.dataframe(analytical_results_df)
        else:
            st.error("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ SQL-Ð·Ð°Ð¿Ñ€Ð¾Ñ.")

st.divider()

# --- Ð¡Ð•ÐšÐ¦Ð˜Ð¯ Ð¤Ð˜Ð›Ð¬Ð¢Ð ÐžÐ’ ---
st.header("ðŸ“Š Ð ÑƒÑ‡Ð½Ñ‹Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹")
with st.expander("ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²", expanded=True):
    st.button("Ð¡Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð²ÑÐµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹", on_click=reset_all_filters, use_container_width=True, type="secondary")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.multiselect("ÐÐ°Ð¿Ñ€ÑÐ¼Ð¾Ðº:", options=filter_options['direction'], key='selected_directions')
    with col2:
        st.multiselect("ÐšÑ€Ð°Ñ—Ð½Ð°-Ð¿Ð°Ñ€Ñ‚Ð½ÐµÑ€:", options=filter_options['countries'], key='selected_countries')
    with col3:
        st.multiselect("Ð’Ð¸Ð´ Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ñƒ:", options=filter_options['transport'], key='selected_transports')

    col4, col5 = st.columns([2,1])
    with col4:
        st.multiselect("Ð Ð¾ÐºÐ¸:", options=filter_options['years'], key='selected_years')
    with col5:
        st.write("Ð’Ð°Ð³Ð° Ð½ÐµÑ‚Ñ‚Ð¾, ÐºÐ³")
        weight_col1, weight_col2 = st.columns(2)
        weight_from = weight_col1.number_input("Ð’Ñ–Ð´", min_value=0, step=100, key="weight_from")
        weight_to = weight_col2.number_input("Ð”Ð¾", min_value=0, step=100, key="weight_to")

    col6, col7, col8 = st.columns(3)
    with col6:
        st.text_input("ÐšÐ¾Ð´ Ð£ÐšÐ¢Ð—Ð•Ð” (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='uktzed_input')
    with col7:
        st.text_input("ÐšÐ¾Ð´ Ð„Ð”Ð ÐŸÐžÐ£ (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='yedrpou_input')
    with col8:
        st.text_input("ÐÐ°Ð·Ð²Ð° ÐºÐ¾Ð¼Ð¿Ð°Ð½Ñ–Ñ— (Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¼Ñƒ):", key='company_input')
    
    search_button_filters = st.button("ðŸ” Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ð·Ð° Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ð¼Ð¸", use_container_width=True, type="primary")

# --- Ð›ÐžÐ“Ð˜ÐšÐ Ð¤Ð˜Ð›Ð¬Ð¢Ð ÐžÐ’ ---
if search_button_filters:
    query_parts = []
    query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]

    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)")
        query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)")
        query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)")
        query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)")
        query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))

    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from")
        query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to")
        query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))

    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"
            conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")

    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)")
        query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))

    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"
            conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    
    if not query_parts:
        st.warning("Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ…Ð¾Ñ‡Ð° Ð± Ð¾Ð´Ð¸Ð½ Ñ„Ñ–Ð»ÑŒÑ‚Ñ€.")
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 1000"
        job_config = QueryJobConfig(query_parameters=query_params)
        st.code(final_query, language='sql')
        with st.spinner("Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ”Ñ‚ÑŒÑÑ Ð·Ð°Ð¿Ð¸Ñ‚..."):
            results_df = run_query(final_query, job_config=job_config)
            st.success(f"Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(results_df)} Ð·Ð°Ð¿Ð¸ÑÑ–Ð².")
            st.dataframe(results_df)
