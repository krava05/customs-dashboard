# ===============================================
# app.py - –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# –í–µ—Ä—Å–∏—è: 20.1
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import re
from io import BytesIO

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
APP_VERSION = "–í–µ—Ä—Å–∏—è 20.1"
st.set_page_config(page_title="–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö", layout="wide")
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- –°–õ–û–í–ê–†–¨ –î–õ–Ø –û–ü–ò–°–ê–ù–ò–Ø –ì–†–£–ü–ü –£–ö–¢–ó–ï–î ---
GROUP_DESCRIPTIONS = {
    '01': '–ñ–∏–≤—ñ —Ç–≤–∞—Ä–∏–Ω–∏', '02': '–ú\'—è—Å–æ —Ç–∞ —ó—Å—Ç—ñ–≤–Ω—ñ —Å—É–±–ø—Ä–æ–¥—É–∫—Ç–∏', '03': '–†–∏–±–∞ —ñ —Ä–∞–∫–æ–ø–æ–¥—ñ–±–Ω—ñ', '04': '–ú–æ–ª–æ—á–Ω—ñ –ø—Ä–æ–¥—É–∫—Ç–∏, —è–π—Ü—è, –º–µ–¥', '05': '–Ü–Ω—à—ñ –ø—Ä–æ–¥—É–∫—Ç–∏ —Ç–≤–∞—Ä–∏–Ω–Ω–æ–≥–æ –ø–æ—Ö–æ–¥–∂–µ–Ω–Ω—è',
    '06': '–ñ–∏–≤—ñ –¥–µ—Ä–µ–≤–∞ —Ç–∞ —ñ–Ω—à—ñ —Ä–æ—Å–ª–∏–Ω–∏', '07': '–û–≤–æ—á—ñ', '08': '–á—Å—Ç—ñ–≤–Ω—ñ –ø–ª–æ–¥–∏ —Ç–∞ –≥–æ—Ä—ñ—Ö–∏', '09': '–ö–∞–≤–∞, —á–∞–π, –ø—Ä—è–Ω–æ—â—ñ', '10': '–ó–µ—Ä–Ω–æ–≤—ñ –∫—É–ª—å—Ç—É—Ä–∏',
    '11': '–ü—Ä–æ–¥—É–∫—Ü—ñ—è –±–æ—Ä–æ—à–Ω–æ–º–µ–ª—å–Ω–æ-–∫—Ä—É–ø\'—è–Ω–æ—ó –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ—Å—Ç—ñ', '12': '–û–ª—ñ–π–Ω–µ –Ω–∞—Å—ñ–Ω–Ω—è —Ç–∞ –ø–ª–æ–¥–∏', '13': '–®–µ–ª–∞–∫, –∫–∞–º–µ–¥—ñ, —Å–º–æ–ª–∏', '14': '–†–æ—Å–ª–∏–Ω–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏ –¥–ª—è –≤–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—è –ø–ª–µ—Ç–µ–Ω–∏—Ö –≤–∏—Ä–æ–±—ñ–≤', '15': '–ñ–∏—Ä–∏ —Ç–∞ –æ–ª—ñ—ó',
    '16': '–ì–æ—Ç–æ–≤—ñ —Ö–∞—Ä—á–æ–≤—ñ –ø—Ä–æ–¥—É–∫—Ç–∏ –∑ –º\'—è—Å–∞, —Ä–∏–±–∏', '17': '–¶—É–∫–æ—Ä —ñ –∫–æ–Ω–¥–∏—Ç–µ—Ä—Å—å–∫—ñ –≤–∏—Ä–æ–±–∏', '18': '–ö–∞–∫–∞–æ —Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∏ –∑ –Ω—å–æ–≥–æ', '19': '–ì–æ—Ç–æ–≤—ñ –ø—Ä–æ–¥—É–∫—Ç–∏ —ñ–∑ –∑–µ—Ä–Ω–∞', '20': '–ü—Ä–æ–¥—É–∫—Ç–∏ –ø–µ—Ä–µ—Ä–æ–±–∫–∏ –æ–≤–æ—á—ñ–≤, –ø–ª–æ–¥—ñ–≤, –≥–æ—Ä—ñ—Ö—ñ–≤',
    '21': '–†—ñ–∑–Ω—ñ —Ö–∞—Ä—á–æ–≤—ñ –ø—Ä–æ–¥—É–∫—Ç–∏', '22': '–ê–ª–∫–æ–≥–æ–ª—å–Ω—ñ —ñ –±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω—ñ –Ω–∞–ø–æ—ó —Ç–∞ –æ—Ü–µ—Ç', '23': '–ó–∞–ª–∏—à–∫–∏ —ñ –≤—ñ–¥—Ö–æ–¥–∏ —Ö–∞—Ä—á–æ–≤–æ—ó –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ—Å—Ç—ñ', '24': '–¢—é—Ç—é–Ω', '25': '–°—ñ–ª—å, —Å—ñ—Ä–∫–∞, –∑–µ–º–ª—ñ —Ç–∞ –∫–∞–º—ñ–Ω–Ω—è, —Ü–µ–º–µ–Ω—Ç',
    '26': '–†—É–¥–∏, —à–ª–∞–∫ —ñ –∑–æ–ª–∞', '27': '–ü–∞–ª–∏–≤–∞ –º—ñ–Ω–µ—Ä–∞–ª—å–Ω—ñ, –Ω–∞—Ñ—Ç–∞', '28': '–ü—Ä–æ–¥—É–∫—Ç–∏ –Ω–µ–æ—Ä–≥–∞–Ω—ñ—á–Ω–æ—ó —Ö—ñ–º—ñ—ó', '29': '–û—Ä–≥–∞–Ω—ñ—á–Ω—ñ —Ö—ñ–º—ñ—á–Ω—ñ —Å–ø–æ–ª—É–∫–∏', '30': '–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–Ω–∞ –ø—Ä–æ–¥—É–∫—Ü—ñ—è',
    '31': '–î–æ–±—Ä–∏–≤–∞', '32': '–ï–∫—Å—Ç—Ä–∞–∫—Ç–∏ –¥—É–±–∏–ª—å–Ω—ñ –∞–±–æ –±–∞—Ä–≤–∏–ª—å–Ω—ñ', '33': '–ï—Ñ—ñ—Ä–Ω—ñ –æ–ª—ñ—ó —Ç–∞ –∫–æ—Å–º–µ—Ç–∏–∫–∞', '34': '–ú–∏–ª–æ, –º–∏–π–Ω—ñ –∑–∞—Å–æ–±–∏, –≤–æ—Å–∫–∏', '35': '–ë—ñ–ª–∫–æ–≤—ñ —Ä–µ—á–æ–≤–∏–Ω–∏, –∫–ª–µ—ó, —Ñ–µ—Ä–º–µ–Ω—Ç–∏',
    '36': '–í–∏–±—É—Ö–æ–≤—ñ —Ä–µ—á–æ–≤–∏–Ω–∏, –ø—ñ—Ä–æ—Ç–µ—Ö–Ω—ñ—á–Ω—ñ –≤–∏—Ä–æ–±–∏', '37': '–§–æ—Ç–æ- —ñ –∫—ñ–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ —Ç–æ–≤–∞—Ä–∏', '38': '–†—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω–∞ —Ö—ñ–º—ñ—á–Ω–∞ –ø—Ä–æ–¥—É–∫—Ü—ñ—è', '39': '–ü–ª–∞—Å—Ç–º–∞—Å–∏, –ø–æ–ª—ñ–º–µ—Ä–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏', '40': '–ö–∞—É—á—É–∫, –≥—É–º–∞ —Ç–∞ –≤–∏—Ä–æ–±–∏ –∑ –Ω–∏—Ö',
    '41': '–ù–µ–æ–±—Ä–æ–±–ª–µ–Ω—ñ —à–∫—É—Ä–∏', '42': '–í–∏—Ä–æ–±–∏ –∑—ñ —à–∫—ñ—Ä–∏', '43': '–•—É—Ç—Ä–æ', '44': '–î–µ—Ä–µ–≤–∏–Ω–∞ —Ç–∞ –≤–∏—Ä–æ–±–∏ –∑ –Ω–µ—ó', '45': '–ö–æ—Ä–æ–∫ —Ç–∞ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ',
    '46': '–í–∏—Ä–æ–±–∏ —ñ–∑ —Å–æ–ª–æ–º–∏', '47': '–ú–∞—Å–∞ –∑ –¥–µ—Ä–µ–≤–∏–Ω–∏', '48': '–ü–∞–ø—ñ—Ä —Ç–∞ –∫–∞—Ä—Ç–æ–Ω', '49': '–î—Ä—É–∫–æ–≤–∞–Ω–∞ –ø—Ä–æ–¥—É–∫—Ü—ñ—è', '50': '–®–æ–≤–∫',
    '51': '–í–æ–≤–Ω–∞, –≤–æ–ª–æ—Å —Ç–≤–∞—Ä–∏–Ω', '52': '–ë–∞–≤–æ–≤–Ω–∞', '53': '–Ü–Ω—à—ñ —Ä–æ—Å–ª–∏–Ω–Ω—ñ —Ç–µ–∫—Å—Ç–∏–ª—å–Ω—ñ –≤–æ–ª–æ–∫–Ω–∞', '54': '–ù–∏—Ç–∫–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –∞–±–æ —à—Ç—É—á–Ω—ñ', '55': '–í–æ–ª–æ–∫–Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –∞–±–æ —à—Ç—É—á–Ω—ñ',
    '56': '–í–∞—Ç–∞, –ø–æ–≤—Å—Ç—å, —Ñ–µ—Ç—Ä', '57': '–ö–∏–ª–∏–º–∏', '58': '–°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ —Ç–∫–∞–Ω–∏–Ω–∏', '59': '–¢–µ–∫—Å—Ç–∏–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏, –ø—Ä–æ—Å–æ—á–µ–Ω—ñ', '60': '–¢—Ä–∏–∫–æ—Ç–∞–∂–Ω—ñ –ø–æ–ª–æ—Ç–Ω–∞',
    '61': '–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏, —Ç—Ä–∏–∫–æ—Ç–∞–∂–Ω—ñ', '62': '–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏, —Ç–µ–∫—Å—Ç–∏–ª—å–Ω—ñ', '63': '–Ü–Ω—à—ñ –≥–æ—Ç–æ–≤—ñ —Ç–µ–∫—Å—Ç–∏–ª—å–Ω—ñ –≤–∏—Ä–æ–±–∏', '64': '–í–∑—É—Ç—Ç—è', '65': '–ì–æ–ª–æ–≤–Ω—ñ —É–±–æ—Ä–∏',
    '66': '–ü–∞—Ä–∞—Å–æ–ª—å–∫–∏, —Ç—Ä–æ—Å—Ç–∏–Ω–∏', '67': '–û–±—Ä–æ–±–ª–µ–Ω–µ –ø—ñ—Ä\'—è —Ç–∞ –ø—É—Ö', '68': '–í–∏—Ä–æ–±–∏ –∑ –∫–∞–º–µ–Ω—é, –≥—ñ–ø—Å—É, —Ü–µ–º–µ–Ω—Ç—É', '69': '–ö–µ—Ä–∞–º—ñ—á–Ω—ñ –≤–∏—Ä–æ–±–∏', '70': '–°–∫–ª–æ —Ç–∞ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ',
    '71': '–ü–µ—Ä–ª–∏, –¥–æ—Ä–æ–≥–æ—Ü—ñ–Ω–Ω–µ –∫–∞–º—ñ–Ω–Ω—è, –±—ñ–∂—É—Ç–µ—Ä—ñ—è', '72': '–ß–æ—Ä–Ω—ñ –º–µ—Ç–∞–ª–∏', '73': '–í–∏—Ä–æ–±–∏ –∑ —á–æ—Ä–Ω–∏—Ö –º–µ—Ç–∞–ª—ñ–≤', '74': '–ú—ñ–¥—å —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω–µ—ó', '75': '–ù—ñ–∫–µ–ª—å —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ',
    '76': '–ê–ª—é–º—ñ–Ω—ñ–π —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ', '78': '–°–≤–∏–Ω–µ—Ü—å —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ', '79': '–¶–∏–Ω–∫ —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ', '80': '–û–ª–æ–≤–æ —ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω—å–æ–≥–æ', '81': '–Ü–Ω—à—ñ –Ω–µ–¥–æ—Ä–æ–≥–æ—Ü—ñ–Ω–Ω—ñ –º–µ—Ç–∞–ª–∏',
    '82': '–Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏, –Ω–æ–∂–æ–≤—ñ –≤–∏—Ä–æ–±–∏', '83': '–Ü–Ω—à—ñ –≤–∏—Ä–æ–±–∏ –∑ –Ω–µ–¥–æ—Ä–æ–≥–æ—Ü—ñ–Ω–Ω–∏—Ö –º–µ—Ç–∞–ª—ñ–≤', '84': '–ú–∞—à–∏–Ω–∏, –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è —ñ –º–µ—Ö–∞–Ω—ñ—á–Ω—ñ –ø—Ä–∏—Å—Ç—Ä–æ—ó', '85': '–ï–ª–µ–∫—Ç—Ä–∏—á–Ω—ñ –º–∞—à–∏–Ω–∏ –π —É—Å—Ç–∞—Ç–∫—É–≤–∞–Ω–Ω—è', '86': '–ó–∞–ª—ñ–∑–Ω–∏—á–Ω–µ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è',
    '87': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ñ –∑–∞—Å–æ–±–∏, –∫—Ä—ñ–º –∑–∞–ª—ñ–∑–Ω–∏—á–Ω–∏—Ö', '88': '–õ—ñ—Ç–∞–ª—å–Ω—ñ –∞–ø–∞—Ä–∞—Ç–∏', '89': '–°—É–¥–Ω–∞, —á–æ–≤–Ω–∏', '90': '–ü—Ä–∏–ª–∞–¥–∏ —Ç–∞ –∞–ø–∞—Ä–∞—Ç–∏ –æ–ø—Ç–∏—á–Ω—ñ, —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ', '91': '–ì–æ–¥–∏–Ω–Ω–∏–∫–∏',
    '92': '–ú—É–∑–∏—á–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏', '93': '–ó–±—Ä–æ—è —Ç–∞ –±–æ—î–ø—Ä–∏–ø–∞—Å–∏', '94': '–ú–µ–±–ª—ñ, –æ—Å–≤—ñ—Ç–ª—é–≤–∞–ª—å–Ω—ñ –ø—Ä–∏–ª–∞–¥–∏', '95': '–Ü–≥—Ä–∞—à–∫–∏, —ñ–≥—Ä–∏ —Ç–∞ —Å–ø–æ—Ä—Ç–∏–≤–Ω–∏–π —ñ–Ω–≤–µ–Ω—Ç–∞—Ä', '96': '–†—ñ–∑–Ω—ñ –ø—Ä–æ–º–∏—Å–ª–æ–≤—ñ —Ç–æ–≤–∞—Ä–∏',
    '97': '–¢–≤–æ—Ä–∏ –º–∏—Å—Ç–µ—Ü—Ç–≤–∞, –ø—Ä–µ–¥–º–µ—Ç–∏ –∫–æ–ª–µ–∫—Ü—ñ–æ–Ω—É–≤–∞–Ω–Ω—è'
}

@st.cache_data
def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Data')
    processed_data = output.getvalue()
    return processed_data

# --- –§–£–ù–ö–¶–ò–ò --- (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

def check_password():
    def password_entered():
        if os.environ.get('K_SERVICE'): correct_password = os.environ.get("APP_PASSWORD")
        else: correct_password = st.secrets.get("APP_PASSWORD")
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True; del st.session_state["password"]
        else: st.session_state["password_correct"] = False
    if st.session_state.get("password_correct", False): return True
    st.text_input("–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø—É", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]: st.error("üòï –ü–∞—Ä–æ–ª—å –Ω–µ–≤—ñ—Ä–Ω–∏–π.")
    return False

def initialize_clients():
    if 'clients_initialized' in st.session_state: return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤ Google: {e}"); st.session_state.client_ready = False

def run_query(query, job_config=None):
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –¥–æ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def get_ai_code_suggestions(product_description):
    if not st.session_state.get('genai_ready', False): return None
    prompt = f"""
    –¢–∏ –µ–∫—Å–ø–µ—Ä—Ç –∑ –º–∏—Ç–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –∫–æ–¥—ñ–≤ –£–ö–¢–ó–ï–î. –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É —Ç–∞ –Ω–∞–¥–∞–π —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –∫–æ–¥—ñ–≤ –£–ö–¢–ó–ï–î.
    –í–∫–ª—é—á–∏ –∫–æ–¥–∏ —Ä—ñ–∑–Ω–æ—ó –¥–æ–≤–∂–∏–Ω–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 4, 6, 10 –∑–Ω–∞–∫—ñ–≤). –¢–≤–æ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ú–ê–Ñ –ë–£–¢–ò –¢–Ü–õ–¨–ö–ò —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON, —â–æ —î —î–¥–∏–Ω–∏–º —Å–ø–∏—Å–∫–æ–º —Ä—è–¥–∫—ñ–≤.
    –ü—Ä–∏–∫–ª–∞–¥ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: ["8517", "851712", "8517120000"] –ù–µ –¥–æ–¥–∞–≤–∞–π –∂–æ–¥–Ω–∏—Ö –æ–ø–∏—Å—ñ–≤, –ø–æ—è—Å–Ω–µ–Ω—å —á–∏ —ñ–Ω—à–æ–≥–æ —Ç–µ–∫—Å—Ç—É –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ JSON-–º–∞—Å–∏–≤—É.
    –û–ü–ò–° –¢–û–í–ê–†–£: "{product_description}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = model.generate_content(prompt, generation_config=generation_config)
        cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        response_json = json.loads(cleaned_text)
        if isinstance(response_json, list) and all(isinstance(i, str) for i in response_json): return response_json
        else: st.error("AI –ø–æ–≤–µ—Ä–Ω—É–≤ –¥–∞–Ω—ñ —É –Ω–µ–æ—á—ñ–∫—É–≤–∞–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ."); return []
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∫–æ–¥—ñ–≤ –≤—ñ–¥ AI: {e}"); return None

def find_and_validate_codes(product_description):
    theoretical_codes = get_ai_code_suggestions(product_description)
    if theoretical_codes is None or not theoretical_codes:
        st.warning("AI –Ω–µ –∑–º—ñ–≥ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –∫–æ–¥–∏. –°–ø—Ä–æ–±—É–π—Ç–µ –∑–º—ñ–Ω–∏—Ç–∏ –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É."); return None, [], []
    unique_codes = list(set(filter(None, theoretical_codes)))
    if not unique_codes:
        st.warning("–í—ñ–¥–ø–æ–≤—ñ–¥—å AI –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–¥—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏."); return None, [], []
    query_parts = []; query_params = []
    for i, code in enumerate(unique_codes):
        param_name = f"code{i}"; query_parts.append(f"STARTS_WITH(kod_uktzed, @{param_name})")
        query_params.append(ScalarQueryParameter(param_name, "STRING", code))
    where_clause = " OR ".join(query_parts)
    validation_query = f"""
    WITH BaseData AS (SELECT kod_uktzed, opis_tovaru, SAFE_CAST(mytna_vartist_hrn AS FLOAT64) as customs_value FROM `{TABLE_ID}` WHERE ({where_clause}) AND kod_uktzed IS NOT NULL),
    RankedDescriptions AS (SELECT kod_uktzed, opis_tovaru, ROW_NUMBER() OVER(PARTITION BY kod_uktzed ORDER BY COUNT(*) DESC) as rn FROM BaseData WHERE opis_tovaru IS NOT NULL GROUP BY kod_uktzed, opis_tovaru),
    Aggregates AS (SELECT kod_uktzed, COUNT(*) as total_declarations, SUM(customs_value) as total_value, AVG(customs_value) as avg_value FROM BaseData GROUP BY kod_uktzed)
    SELECT a.kod_uktzed AS `–ö–æ–¥ –£–ö–¢–ó–ï–î –≤ –±–∞–∑—ñ`, rd.opis_tovaru AS `–ù–∞–π—á–∞—Å—Ç—ñ—à–∏–π –æ–ø–∏—Å –≤ –±–∞–∑—ñ`, a.total_declarations AS `–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ–∫–ª–∞—Ä–∞—Ü—ñ–π`, a.total_value AS `–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω`, a.avg_value AS `–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω`
    FROM Aggregates a JOIN RankedDescriptions rd ON a.kod_uktzed = rd.kod_uktzed WHERE rd.rn = 1 ORDER BY a.total_declarations DESC LIMIT 50
    """
    job_config = QueryJobConfig(query_parameters=query_params); validated_df = run_query(validation_query, job_config=job_config)
    if validated_df is not None and not validated_df.empty:
        pd.options.display.float_format = '{:,.2f}'.format
        validated_df['–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'] = validated_df['–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "N/A")
        validated_df['–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'] = validated_df['–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "N/A")
    found_prefixes = set()
    if validated_df is not None and not validated_df.empty:
        db_codes_series = validated_df["–ö–æ–¥ –£–ö–¢–ó–ï–î –≤ –±–∞–∑—ñ"]
        for db_code in db_codes_series:
            for ai_code in unique_codes:
                if str(db_code).startswith(ai_code): found_prefixes.add(ai_code)
    unfound_codes = set(unique_codes) - found_prefixes
    return validated_df, list(found_prefixes), list(unfound_codes)

@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['–Ü–º–ø–æ—Ä—Ç', '–ï–∫—Å–ø–æ—Ä—Ç']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    query_months = f"SELECT DISTINCT EXTRACT(MONTH FROM SAFE_CAST(data_deklaracii AS DATE)) as month FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY month"
    options['months'] = list(run_query(query_months)['month'].dropna().astype(int))
    query_groups = f"SELECT DISTINCT SUBSTR(kod_uktzed, 1, 2) as group_code FROM `{TABLE_ID}` WHERE LENGTH(kod_uktzed) >= 2 ORDER BY group_code"
    options['groups'] = list(run_query(query_groups)['group_code'].dropna())
    return options

def reset_all_filters():
    st.session_state.selected_directions = []; st.session_state.selected_countries = []; st.session_state.selected_transports = []
    st.session_state.selected_years = []; st.session_state.selected_months = []; st.session_state.selected_groups = []
    st.session_state.selected_positions = []; st.session_state.weight_from = 0; st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""; st.session_state.yedrpou_input = ""; st.session_state.company_input = ""
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 3: –û—á–∏—Å—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ ---
    if 'results_df' in st.session_state:
        del st.session_state.results_df

# --- –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---

if not check_password():
    st.stop()

st.markdown("""
<style>
body { color: #111; }
.version-badge { position: fixed; top: 55px; right: 15px; padding: 5px 10px; border-radius: 8px; background-color: #f0f2f6; color: #31333F; font-size: 12px; z-index: 1000; }
</style>
""", unsafe_allow_html=True)
st.markdown(f'<p class="version-badge">{APP_VERSION}</p>', unsafe_allow_html=True)

st.title("–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö üìà")
initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ Google BigQuery."); st.stop()

st.header("ü§ñ AI-–ø–æ–º—ñ—á–Ω–∏–∫ –ø–æ –∫–æ–¥–∞–º –£–ö–¢–ó–ï–î")
ai_code_description = st.text_input("–í–≤–µ–¥—ñ—Ç—å –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É –¥–ª—è –ø–æ—à—É–∫—É —Ä–µ–∞–ª—å–Ω–∏—Ö –∫–æ–¥—ñ–≤ —É –≤–∞—à—ñ–π –±–∞–∑—ñ:", key="ai_code_helper_input")
if st.button("üí° –ó–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–æ–¥–∏", type="primary"):
    if ai_code_description:
        with st.spinner("AI –ø—ñ–¥–±–∏—Ä–∞—î –∫–æ–¥–∏, –∞ –º–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —ó—Ö —É –±–∞–∑—ñ..."):
            validated_df, found, unfound = find_and_validate_codes(ai_code_description)
            st.session_state.validated_df = validated_df; st.session_state.found_ai_codes = found; st.session_state.unfound_ai_codes = unfound
    else: st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É.")

if 'validated_df' in st.session_state:
    validated_df = st.session_state.validated_df
    if validated_df is not None and not validated_df.empty:
        st.success(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(validated_df)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –∫–æ–¥—ñ–≤ —É –≤–∞—à—ñ–π –±–∞–∑—ñ –¥–∞–Ω–∏—Ö:")
        st.dataframe(validated_df, use_container_width=True)
        if st.session_state.found_ai_codes:
            st.info(f"–ö–æ–¥–∏ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —Ü–∏–º–∏ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è–º–∏ AI: `{', '.join(st.session_state.found_ai_codes)}`")
    else: st.warning("üö´ –£ –≤–∞—à—ñ–π –±–∞–∑—ñ –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ –∫–æ–¥—É, —â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è–º AI.")
    if st.session_state.unfound_ai_codes:
        st.caption(f"–¢–µ–æ—Ä–µ—Ç–∏—á–Ω—ñ –∫–æ–¥–∏ –≤—ñ–¥ AI, –¥–ª—è —è–∫–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–±—ñ–≥—ñ–≤: `{', '.join(st.session_state.unfound_ai_codes)}`")
    if st.button("–û—á–∏—Å—Ç–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç AI", type="secondary"):
        keys_to_delete = ['validated_df', 'found_ai_codes', 'unfound_ai_codes']
        for key in keys_to_delete:
            if key in st.session_state: del st.session_state[key]
        st.rerun()

st.divider()

# --- –ë–õ–û–ö –†–£–ß–ù–´–• –§–ò–õ–¨–¢–†–û–í ---
filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

st.header("üìä –†—É—á–Ω—ñ —Ñ—ñ–ª—å—Ç—Ä–∏")
st.button("–°–∫–∏–Ω—É—Ç–∏ –≤—Å—ñ —Ñ—ñ–ª—å—Ç—Ä–∏", on_click=reset_all_filters, use_container_width=True, type="secondary")
st.markdown("---")

c1, c2, c3 = st.columns(3)
with c1: st.multiselect("–ù–∞–ø—Ä—è–º–æ–∫:", options=filter_options['direction'], key='selected_directions')
with c2: st.multiselect("–ö—Ä–∞—ó–Ω–∞-–ø–∞—Ä—Ç–Ω–µ—Ä:", options=filter_options['countries'], key='selected_countries')
with c3: st.multiselect("–í–∏–¥ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É:", options=filter_options['transport'], key='selected_transports')

c4, c5, c6 = st.columns(3)
with c4: st.multiselect("–†–æ–∫–∏:", options=filter_options['years'], key='selected_years')
with c5: st.multiselect("–ú—ñ—Å—è—Ü—ñ:", options=filter_options['months'], key='selected_months')
with c6:
    w_col1, w_col2 = st.columns(2)
    w_col1.number_input("–í–∞–≥–∞ –≤—ñ–¥, –∫–≥", min_value=0, step=100, key="weight_from")
    w_col2.number_input("–í–∞–≥–∞ –¥–æ, –∫–≥", min_value=0, step=100, key="weight_to")

c7, c8, c9 = st.columns(3)
with c7: st.text_input("–ö–æ–¥ –£–ö–¢–ó–ï–î (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='uktzed_input')
with c8: st.text_input("–ö–æ–¥ –Ñ–î–†–ü–û–£ (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='yedrpou_input')
with c9: st.text_input("–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='company_input')

st.markdown("---")
cg, cp = st.columns([1, 3])
with cg:
    group_options = [f"{g} - {GROUP_DESCRIPTIONS.get(g, '–ù–µ–≤—ñ–¥–æ–º–∞ –≥—Ä—É–ø–∞')}" for g in filter_options['groups']]
    st.multiselect("–¢–æ–≤–∞—Ä–Ω–∞ –≥—Ä—É–ø–∞ (2 —Ü–∏—Ñ—Ä–∏):", options=group_options, key='selected_groups')
with cp:
    selected_group_codes = [g.split(' - ')[0] for g in st.session_state.get('selected_groups', [])]
    position_options = []
    if selected_group_codes:
        group_conditions = " OR ".join([f"STARTS_WITH(kod_uktzed, '{g}')" for g in selected_group_codes])
        query_positions = f"""
        WITH PositionCounts AS (
            SELECT SUBSTR(kod_uktzed, 1, 4) AS pos_code, opis_tovaru, COUNT(*) AS frequency
            FROM `{TABLE_ID}` WHERE ({group_conditions}) AND LENGTH(kod_uktzed) >= 4 GROUP BY pos_code, opis_tovaru
        ),
        RankedPositions AS (
            SELECT pos_code, opis_tovaru, ROW_NUMBER() OVER(PARTITION BY pos_code ORDER BY frequency DESC) AS rn
            FROM PositionCounts
        )
        SELECT pos_code, opis_tovaru AS pos_description FROM RankedPositions WHERE rn = 1 ORDER BY pos_code
        """
        position_df = run_query(query_positions)
        if not position_df.empty:
            for _, row in position_df.iterrows():
                position_options.append(f"{row['pos_code']} - {row['pos_description']}")
    st.multiselect("–¢–æ–≤–∞—Ä–Ω–∞ –ø–æ–∑–∏—Ü—ñ—è (4 —Ü–∏—Ñ—Ä–∏):", options=position_options, key='selected_positions', disabled=not selected_group_codes)

st.markdown("---")
search_button_filters = st.button("üîç –ó–Ω–∞–π—Ç–∏ –∑–∞ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏", use_container_width=True, type="primary")

# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 4: –õ–æ–≥–∏–∫–∞ –≤—ã–Ω–µ—Å–µ–Ω–∞ –∏–∑-–ø–æ–¥ –∫–Ω–æ–ø–∫–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ ---
# –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–µ—Å—Å–∏—é
if search_button_filters:
    query_parts = []; query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]
    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)"); query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)"); query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)"); query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)"); query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))
    if st.session_state.selected_months:
        query_parts.append("EXTRACT(MONTH FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@months)"); query_params.append(ArrayQueryParameter("months", "INT64", st.session_state.selected_months))
    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from"); query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to"); query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))
    
    selected_group_codes = [g.split(' - ')[0] for g in st.session_state.get('selected_groups', [])]
    if st.session_state.get('selected_positions', []):
        position_codes = [p.split(' - ')[0] for p in st.session_state.selected_positions]
        conditions = [f"STARTS_WITH(kod_uktzed, '{p}')" for p in position_codes]
        query_parts.append(f"({' OR '.join(conditions)})")
    elif selected_group_codes:
        conditions = [f"STARTS_WITH(kod_uktzed, '{g}')" for g in selected_group_codes]
        query_parts.append(f"({' OR '.join(conditions)})")
    
    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"; conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)"); query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))
    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"; conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    
    if not query_parts:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ—ñ–ª—å—Ç—Ä.")
        st.session_state.results_df = pd.DataFrame() # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –µ—Å–ª–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ—Ç
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 5000"
        job_config = QueryJobConfig(query_parameters=query_params)
        with st.spinner("–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –∑–∞–ø–∏—Ç..."):
            st.session_state.results_df = run_query(final_query, job_config=job_config)

# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ —Å–µ—Å—Å–∏–∏
if 'results_df' in st.session_state and st.session_state.results_df is not None:
    results_df = st.session_state.results_df.copy()
    st.success(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –∑–∞–ø–∏—Å—ñ–≤.")
    
    if not results_df.empty:
        ukrainian_column_names = {
            'data_deklaracii': '–î–∞—Ç–∞ –¥–µ–∫–ª–∞—Ä–∞—Ü—ñ—ó', 'napryamok': '–ù–∞–ø—Ä—è–º–æ–∫', 'nazva_kompanii': '–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó',
            'kod_yedrpou': '–ö–æ–¥ –Ñ–î–†–ü–û–£', 'kraina_partner': '–ö—Ä–∞—ó–Ω–∞-–ø–∞—Ä—Ç–Ω–µ—Ä', 'kod_uktzed': '–ö–æ–¥ –£–ö–¢–ó–ï–î',
            'opis_tovaru': '–û–ø–∏—Å —Ç–æ–≤–∞—Ä—É', 'mytna_vartist_hrn': '–ú–∏—Ç–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å, –≥—Ä–Ω', 'vaha_netto_kg': '–í–∞–≥–∞ –Ω–µ—Ç—Ç–æ, –∫–≥',
            'vyd_transportu': '–í–∏–¥ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É'
        }
        results_df = results_df.rename(columns=ukrainian_column_names)
        
        numeric_cols = ['–ú–∏—Ç–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å, –≥—Ä–Ω', '–í–∞–≥–∞ –Ω–µ—Ç—Ç–æ, –∫–≥']
        for col in numeric_cols:
            if col in results_df.columns:
                results_df[col] = pd.to_numeric(results_df[col], errors='coerce')
        
        st.dataframe(results_df)

        excel_data = to_excel(results_df)
        st.download_button(
            label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç—ñ Excel",
            data=excel_data,
            file_name='customs_data_export.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
