# ===============================================
# app.py - –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# –í–µ—Ä—Å–∏—è: 17.1
# ===============================================

import os
import streamlit as st
from google.cloud import bigquery
from google.cloud.bigquery import QueryJobConfig, ArrayQueryParameter, ScalarQueryParameter
import pandas as pd
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import re

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
APP_VERSION = "–í–µ—Ä—Å–∏—è 17.1"
st.set_page_config(page_title="–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö", layout="wide")
PROJECT_ID = "ua-customs-analytics"
TABLE_ID = f"{PROJECT_ID}.ua_customs_data.declarations"

# --- –§–£–ù–ö–¶–ò–ò ---

def check_password():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é."""
    def password_entered():
        if os.environ.get('K_SERVICE'):
            correct_password = os.environ.get("APP_PASSWORD")
        else:
            correct_password = st.secrets.get("APP_PASSWORD")
        
        if st.session_state.get("password") and st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if st.session_state.get("password_correct", False):
        return True
    
    st.text_input("–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø—É", type="password", on_change=password_entered, key="password")
    if "password_correct" in st.session_state and not st.session_state["password_correct"]:
        st.error("üòï –ü–∞—Ä–æ–ª—å –Ω–µ–≤—ñ—Ä–Ω–∏–π.")
    return False

def initialize_clients():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç—ã –¥–ª—è BigQuery –∏ Generative AI."""
    if 'clients_initialized' in st.session_state:
        return
    try:
        if os.environ.get('K_SERVICE'):
            st.session_state.bq_client = bigquery.Client(project=PROJECT_ID)
            api_key = os.environ.get("GOOGLE_AI_API_KEY")
        else:
            st.session_state.bq_client = bigquery.Client()
            api_key = st.secrets.get("GOOGLE_AI_API_KEY")
        
        if api_key:
            genai.configure(api_key=api_key)
            st.session_state.genai_ready = True
            
        st.session_state.clients_initialized = True
        st.session_state.client_ready = True
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤ Google: {e}")
        st.session_state.client_ready = False

def run_query(query, job_config=None):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ BigQuery –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame."""
    if st.session_state.get('client_ready', False):
        try:
            return st.session_state.bq_client.query(query, job_config=job_config).to_dataframe()
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –¥–æ BigQuery: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def get_ai_code_suggestions(product_description):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç AI —Å–ø–∏—Å–æ–∫ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–¥–æ–≤ –£–ö–¢–ó–ï–î."""
    if not st.session_state.get('genai_ready', False):
        return None
    
    prompt = f"""
    –¢–∏ –µ–∫—Å–ø–µ—Ä—Ç –∑ –º–∏—Ç–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –∫–æ–¥—ñ–≤ –£–ö–¢–ó–ï–î.
    –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É —Ç–∞ –Ω–∞–¥–∞–π —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –∫–æ–¥—ñ–≤ –£–ö–¢–ó–ï–î.
    –í–∫–ª—é—á–∏ –∫–æ–¥–∏ —Ä—ñ–∑–Ω–æ—ó –¥–æ–≤–∂–∏–Ω–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 4, 6, 10 –∑–Ω–∞–∫—ñ–≤).

    –¢–≤–æ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ú–ê–Ñ –ë–£–¢–ò –¢–Ü–õ–¨–ö–ò —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON, —â–æ —î —î–¥–∏–Ω–∏–º —Å–ø–∏—Å–∫–æ–º —Ä—è–¥–∫—ñ–≤.
    –ü—Ä–∏–∫–ª–∞–¥ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: ["8517", "851712", "8517120000"]
    –ù–µ –¥–æ–¥–∞–≤–∞–π –∂–æ–¥–Ω–∏—Ö –æ–ø–∏—Å—ñ–≤, –ø–æ—è—Å–Ω–µ–Ω—å —á–∏ —ñ–Ω—à–æ–≥–æ —Ç–µ–∫—Å—Ç—É –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ JSON-–º–∞—Å–∏–≤—É.

    –û–ü–ò–° –¢–û–í–ê–†–£: "{product_description}"
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = model.generate_content(prompt, generation_config=generation_config)
        
        cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        response_json = json.loads(cleaned_text)

        if isinstance(response_json, list) and all(isinstance(i, str) for i in response_json):
            return response_json
        else:
            st.error("AI –ø–æ–≤–µ—Ä–Ω—É–≤ –¥–∞–Ω—ñ —É –Ω–µ–æ—á—ñ–∫—É–≤–∞–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ.")
            return []
            
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∫–æ–¥—ñ–≤ –≤—ñ–¥ AI: {e}")
        return None

def find_and_validate_codes(product_description):
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–¥—ã –æ—Ç AI, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –Ω–∞–ª–∏—á–∏–µ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å."""
    
    theoretical_codes = get_ai_code_suggestions(product_description)
    
    if theoretical_codes is None or not theoretical_codes:
        st.warning("AI –Ω–µ –∑–º—ñ–≥ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –∫–æ–¥–∏. –°–ø—Ä–æ–±—É–π—Ç–µ –∑–º—ñ–Ω–∏—Ç–∏ –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É.")
        return None, [], []

    unique_codes = list(set(filter(None, theoretical_codes)))
    if not unique_codes:
        st.warning("–í—ñ–¥–ø–æ–≤—ñ–¥—å AI –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–¥—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏.")
        return None, [], []

    query_parts = []
    query_params = []
    for i, code in enumerate(unique_codes):
        param_name = f"code{i}"
        query_parts.append(f"STARTS_WITH(kod_uktzed, @{param_name})")
        query_params.append(ScalarQueryParameter(param_name, "STRING", code))
        
    where_clause = " OR ".join(query_parts)
    
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –£–±—Ä–∞–Ω–∞ –∑–∞–ø—è—Ç–∞—è –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫ ---
    validation_query = f"""
    WITH BaseData AS (
      SELECT
        kod_uktzed,
        opis_tovaru,
        SAFE_CAST(mytna_vartist_hrn AS FLOAT64) as customs_value
      FROM `{TABLE_ID}`
      WHERE ({where_clause}) AND kod_uktzed IS NOT NULL
    ),
    RankedDescriptions AS (
      SELECT
        kod_uktzed,
        opis_tovaru,
        ROW_NUMBER() OVER(PARTITION BY kod_uktzed ORDER BY COUNT(*) DESC) as rn
      FROM BaseData
      WHERE opis_tovaru IS NOT NULL
      GROUP BY kod_uktzed, opis_tovaru
    ),
    Aggregates AS (
      SELECT
        kod_uktzed,
        COUNT(*) as total_declarations,
        SUM(customs_value) as total_value,
        AVG(customs_value) as avg_value
      FROM BaseData
      GROUP BY kod_uktzed
    )
    SELECT
      a.kod_uktzed AS `–ö–æ–¥ –£–ö–¢–ó–ï–î –≤ –±–∞–∑—ñ`,
      rd.opis_tovaru AS `–ù–∞–π—á–∞—Å—Ç—ñ—à–∏–π –æ–ø–∏—Å –≤ –±–∞–∑—ñ`,
      a.total_declarations AS `–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ–∫–ª–∞—Ä–∞—Ü—ñ–π`,
      a.total_value AS `–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω`,
      a.avg_value AS `–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω`
    FROM Aggregates a
    JOIN RankedDescriptions rd ON a.kod_uktzed = rd.kod_uktzed
    WHERE rd.rn = 1
    ORDER BY a.total_declarations DESC
    LIMIT 50
    """
    
    job_config = QueryJobConfig(query_parameters=query_params)
    validated_df = run_query(validation_query, job_config=job_config)

    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å –Ω–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ ---
    if validated_df is not None and not validated_df.empty:
        pd.options.display.float_format = '{:,.2f}'.format
        validated_df['–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'] = validated_df['–ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "N/A")
        validated_df['–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'] = validated_df['–°–µ—Ä–µ–¥–Ω—è –≤–∞—Ä—Ç—ñ—Å—Ç—å –≥—Ä–Ω'].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "N/A")
    
    found_prefixes = set()
    if validated_df is not None and not validated_df.empty:
        db_codes_series = validated_df["–ö–æ–¥ –£–ö–¢–ó–ï–î –≤ –±–∞–∑—ñ"]
        for db_code in db_codes_series:
            for ai_code in unique_codes:
                if str(db_code).startswith(ai_code):
                    found_prefixes.add(ai_code)
    
    unfound_codes = set(unique_codes) - found_prefixes
    
    return validated_df, list(found_prefixes), list(unfound_codes)


@st.cache_data(ttl=3600)
def get_filter_options():
    options = {}
    options['direction'] = ['–Ü–º–ø–æ—Ä—Ç', '–ï–∫—Å–ø–æ—Ä—Ç']
    query_countries = f"SELECT DISTINCT kraina_partner FROM `{TABLE_ID}` WHERE kraina_partner IS NOT NULL ORDER BY kraina_partner"
    options['countries'] = list(run_query(query_countries)['kraina_partner'])
    query_transport = f"SELECT DISTINCT vyd_transportu FROM `{TABLE_ID}` WHERE vyd_transportu IS NOT NULL ORDER BY vyd_transportu"
    options['transport'] = list(run_query(query_transport)['vyd_transportu'])
    query_years = f"SELECT DISTINCT EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) as year FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY year DESC"
    options['years'] = list(run_query(query_years)['year'].dropna().astype(int))
    query_months = f"SELECT DISTINCT EXTRACT(MONTH FROM SAFE_CAST(data_deklaracii AS DATE)) as month FROM `{TABLE_ID}` WHERE data_deklaracii IS NOT NULL ORDER BY month"
    options['months'] = list(run_query(query_months)['month'].dropna().astype(int))
    return options

def reset_all_filters():
    st.session_state.selected_directions = []
    st.session_state.selected_countries = []
    st.session_state.selected_transports = []
    st.session_state.selected_years = []
    st.session_state.selected_months = []
    st.session_state.weight_from = 0
    st.session_state.weight_to = 0
    st.session_state.uktzed_input = ""
    st.session_state.yedrpou_input = ""
    st.session_state.company_input = ""

# --- –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---

if not check_password():
    st.stop()

st.markdown("""
<style>
.version-badge {
    position: fixed;
    top: 55px;
    right: 15px;
    padding: 5px 10px;
    border-radius: 8px;
    background-color: #f0f2f6;
    color: #31333F;
    font-size: 12px;
    z-index: 1000;
}
</style>
""", unsafe_allow_html=True)
st.markdown(f'<p class="version-badge">{APP_VERSION}</p>', unsafe_allow_html=True)

st.title("–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ú–∏—Ç–Ω–∏—Ö –î–∞–Ω–∏—Ö üìà")

initialize_clients()
if not st.session_state.get('client_ready', False):
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ Google BigQuery.")
    st.stop()

# --- –ë–õ–û–ö AI-–ü–û–ú–û–©–ù–ò–ö–ê ---
st.header("ü§ñ AI-–ø–æ–º—ñ—á–Ω–∏–∫ –ø–æ –∫–æ–¥–∞–º –£–ö–¢–ó–ï–î")
ai_code_description = st.text_input("–í–≤–µ–¥—ñ—Ç—å –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É –¥–ª—è –ø–æ—à—É–∫—É —Ä–µ–∞–ª—å–Ω–∏—Ö –∫–æ–¥—ñ–≤ —É –≤–∞—à—ñ–π –±–∞–∑—ñ:", key="ai_code_helper_input")

if st.button("üí° –ó–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–æ–¥–∏", type="primary"):
    if ai_code_description:
        with st.spinner("AI –ø—ñ–¥–±–∏—Ä–∞—î –∫–æ–¥–∏, –∞ –º–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —ó—Ö —É –±–∞–∑—ñ..."):
            validated_df, found, unfound = find_and_validate_codes(ai_code_description)
            st.session_state.validated_df = validated_df
            st.session_state.found_ai_codes = found
            st.session_state.unfound_ai_codes = unfound
    else:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É.")

if 'validated_df' in st.session_state:
    validated_df = st.session_state.validated_df
    
    if validated_df is not None and not validated_df.empty:
        st.success(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(validated_df)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –∫–æ–¥—ñ–≤ —É –≤–∞—à—ñ–π –±–∞–∑—ñ –¥–∞–Ω–∏—Ö:")
        st.dataframe(validated_df, use_container_width=True)
        if st.session_state.found_ai_codes:
            st.info(f"–ö–æ–¥–∏ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —Ü–∏–º–∏ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è–º–∏ AI: `{', '.join(st.session_state.found_ai_codes)}`")
    else:
        st.warning("üö´ –£ –≤–∞—à—ñ–π –±–∞–∑—ñ –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ –∫–æ–¥—É, —â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è–º AI.")

    if st.session_state.unfound_ai_codes:
        st.caption(f"–¢–µ–æ—Ä–µ—Ç–∏—á–Ω—ñ –∫–æ–¥–∏ –≤—ñ–¥ AI, –¥–ª—è —è–∫–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–±—ñ–≥—ñ–≤: `{', '.join(st.session_state.unfound_ai_codes)}`")

    if st.button("–û—á–∏—Å—Ç–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç AI", type="secondary"):
        keys_to_delete = ['validated_df', 'found_ai_codes', 'unfound_ai_codes']
        for key in keys_to_delete:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

st.divider()

# --- –ë–õ–û–ö –†–£–ß–ù–´–• –§–ò–õ–¨–¢–†–û–í ---
filter_options = get_filter_options()
if 'selected_directions' not in st.session_state:
    reset_all_filters()

st.header("üìä –†—É—á–Ω—ñ —Ñ—ñ–ª—å—Ç—Ä–∏")
with st.expander("–ü–∞–Ω–µ–ª—å –§—ñ–ª—å—Ç—Ä—ñ–≤", expanded=True):
    st.button("–°–∫–∏–Ω—É—Ç–∏ –≤—Å—ñ —Ñ—ñ–ª—å—Ç—Ä–∏", on_click=reset_all_filters, use_container_width=True, type="secondary")
    st.markdown("---")
    
    # –í–µ—Ä—Ö–Ω–∏–π —Ä—è–¥
    col1, col2, col3, col4, col5 = st.columns([2, 3, 2, 1, 1])
    with col1:
        st.multiselect("–ù–∞–ø—Ä—è–º–æ–∫:", options=filter_options['direction'], key='selected_directions')
    with col2:
        st.multiselect("–ö—Ä–∞—ó–Ω–∞-–ø–∞—Ä—Ç–Ω–µ—Ä:", options=filter_options['countries'], key='selected_countries')
    with col3:
        st.multiselect("–í–∏–¥ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É:", options=filter_options['transport'], key='selected_transports')
    with col4:
        st.multiselect("–†–æ–∫–∏:", options=filter_options['years'], key='selected_years')
    with col5:
        st.multiselect("–ú—ñ—Å—è—Ü—ñ:", options=filter_options['months'], key='selected_months')

    # –ù–∏–∂–Ω–∏–π —Ä—è–¥
    col6, col7, col8, col9 = st.columns(4)
    with col6:
        w_col1, w_col2 = st.columns(2)
        w_col1.number_input("–í–∞–≥–∞ –≤—ñ–¥, –∫–≥", min_value=0, step=100, key="weight_from")
        w_col2.number_input("–í–∞–≥–∞ –¥–æ, –∫–≥", min_value=0, step=100, key="weight_to")
    with col7:
        st.text_input("–ö–æ–¥ –£–ö–¢–ó–ï–î (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='uktzed_input')
    with col8:
        st.text_input("–ö–æ–¥ –Ñ–î–†–ü–û–£ (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='yedrpou_input')
    with col9:
        st.text_input("–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó (—á–µ—Ä–µ–∑ –∫–æ–º—É):", key='company_input')
    
    search_button_filters = st.button("üîç –ó–Ω–∞–π—Ç–∏ –∑–∞ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏", use_container_width=True, type="primary")

if search_button_filters:
    query_parts = []; query_params = []
    def process_text_input(input_str): return [item.strip() for item in input_str.split(',') if item.strip()]
    if st.session_state.selected_directions:
        query_parts.append("napryamok IN UNNEST(@directions)")
        query_params.append(ArrayQueryParameter("directions", "STRING", st.session_state.selected_directions))
    if st.session_state.selected_countries:
        query_parts.append("kraina_partner IN UNNEST(@countries)")
        query_params.append(ArrayQueryParameter("countries", "STRING", st.session_state.selected_countries))
    if st.session_state.selected_transports:
        query_parts.append("vyd_transportu IN UNNEST(@transports)")
        query_params.append(ArrayQueryParameter("transports", "STRING", st.session_state.selected_transports))
    if st.session_state.selected_years:
        query_parts.append("EXTRACT(YEAR FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@years)")
        query_params.append(ArrayQueryParameter("years", "INT64", st.session_state.selected_years))
    if st.session_state.selected_months:
        query_parts.append("EXTRACT(MONTH FROM SAFE_CAST(data_deklaracii AS DATE)) IN UNNEST(@months)")
        query_params.append(ArrayQueryParameter("months", "INT64", st.session_state.selected_months))
    if st.session_state.weight_from > 0:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) >= @weight_from")
        query_params.append(ScalarQueryParameter("weight_from", "FLOAT64", st.session_state.weight_from))
    if st.session_state.weight_to > 0 and st.session_state.weight_to >= st.session_state.weight_from:
        query_parts.append("SAFE_CAST(vaha_netto_kg AS FLOAT64) <= @weight_to")
        query_params.append(ScalarQueryParameter("weight_to", "FLOAT64", st.session_state.weight_to))
    uktzed_list = process_text_input(st.session_state.uktzed_input)
    if uktzed_list:
        conditions = []
        for i, item in enumerate(uktzed_list):
            param_name = f"uktzed{i}"
            conditions.append(f"kod_uktzed LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"{item}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    yedrpou_list = process_text_input(st.session_state.yedrpou_input)
    if yedrpou_list:
        query_parts.append("kod_yedrpou IN UNNEST(@yedrpou)")
        query_params.append(ArrayQueryParameter("yedrpou", "STRING", yedrpou_list))
    company_list = process_text_input(st.session_state.company_input)
    if company_list:
        conditions = []
        for i, item in enumerate(company_list):
            param_name = f"company{i}"
            conditions.append(f"UPPER(nazva_kompanii) LIKE @{param_name}")
            query_params.append(ScalarQueryParameter(param_name, "STRING", f"%{item.upper()}%"))
        query_parts.append(f"({' OR '.join(conditions)})")
    
    if not query_parts:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ—ñ–ª—å—Ç—Ä.")
    else:
        where_clause = " AND ".join(query_parts)
        final_query = f"SELECT * FROM `{TABLE_ID}` WHERE {where_clause} LIMIT 5000"
        job_config = QueryJobConfig(query_parameters=query_params)
        with st.spinner("–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –∑–∞–ø–∏—Ç..."):
            results_df = run_query(final_query, job_config=job_config)
            st.success(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –∑–∞–ø–∏—Å—ñ–≤.")
            st.dataframe(results_df)
